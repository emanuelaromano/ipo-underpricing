{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.decomposition import PCA\n",
    "from custom_transformers import LogTransformer\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./output_csv', exist_ok=True)\n",
    "df = pd.read_csv(\"../build_dataset/output_csv/bloomberg_data.csv\")\n",
    "df = df.dropna(subset=['Offer To 1st Close'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_features(df):\n",
    "    \"\"\"\n",
    "    Convert the 'Trade Date (US)' column to separate columns for\n",
    "    month, day, and year, and drop the original 'Trade Date (US)' column.\n",
    "\n",
    "    Also, convert Offer To 1st Close to a binary classification (Underpriced\n",
    "    column) and drop original column.\n",
    "    \"\"\"\n",
    "    df['Trade Date (US)'] = pd.to_datetime(df['Trade Date (US)'])\n",
    "    df['Trade Month'] = df['Trade Date (US)'].dt.month\n",
    "    df['Trade Day'] = df['Trade Date (US)'].dt.day\n",
    "    df['Trade Year'] = df['Trade Date (US)'].dt.year\n",
    "    df['Underpriced'] = df['Offer To 1st Close'].apply(lambda x: 1 if x < 0 else 0)  \n",
    "\n",
    "    df = df.sort_values('Trade Date (US)')\n",
    "    df['Prev_5_IPOs_Underpriced'] = df['Underpriced'].shift(1).rolling(window=5, min_periods=1).mean()\n",
    "    df['Prev_5_IPOs_Underpriced'] = df['Prev_5_IPOs_Underpriced'].apply(lambda x: 1 if x >= 0.6 else 0)\n",
    "    df.drop(columns=['Trade Date (US)'], inplace=True)\n",
    "    df.drop(columns=['Offer To 1st Close'], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_convert_features = convert_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(columns,df):\n",
    "    \"\"\"\n",
    "    Drop the specified columns from the DataFrame.\n",
    "    \"\"\"\n",
    "    df = df.drop(columns=columns)\n",
    "    return df\n",
    "\n",
    "df_drop_columns = drop_columns(['Issuer Ticker',\n",
    "                                'Issuer Name',\n",
    "                                'Filing Term Price Range',\n",
    "                                'cusip',\n",
    "                                'Priced Range'],\n",
    "                                df_convert_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(df):\n",
    "    \"\"\"\n",
    "    Split the DataFrame into development and testing sets, using stratified sampling, \n",
    "    and encode the features.\n",
    "    \"\"\"\n",
    "\n",
    "    X = df.drop(columns=['Underpriced'])\n",
    "    y = df['Underpriced']\n",
    "\n",
    "    assert y.isnull().sum() == 0, \"Target variable contains missing values\"\n",
    "    \n",
    "    X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=0.2, random_state=42, shuffle=True, stratify=y_dev)\n",
    "\n",
    "    # FILL MISSING VALUES\n",
    "    for col in X_train.columns:\n",
    "        if col in ['Trade Month', 'Trade Day', 'Trade Year']:\n",
    "            X_train[col] = X_train[col].fillna(X_train[col].mode()[0])\n",
    "            X_val[col] = X_val[col].fillna(X_train[col].mode()[0])\n",
    "            X_test[col] = X_test[col].fillna(X_train[col].mode()[0])\n",
    "        elif X_train[col].dtype == 'object' and col not in ['Trade Month', 'Trade Day', 'Trade Year']:\n",
    "            X_train[col] = X_train[col].fillna(X_train[col].mode()[0])\n",
    "            X_val[col] = X_val[col].fillna(X_train[col].mode()[0])\n",
    "            X_test[col] = X_test[col].fillna(X_train[col].mode()[0])\n",
    "        else:\n",
    "            X_train[col] = X_train[col].fillna(X_train[col].mean())\n",
    "            X_val[col] = X_val[col].fillna(X_train[col].mean())\n",
    "            X_test[col] = X_test[col].fillna(X_test[col].mean())\n",
    "\n",
    "\n",
    "    # ENCODING FEATURES\n",
    "    oe_columns = ['Trade Month', 'Trade Day', 'Trade Year']\n",
    "    ohe_columns = ['Industry Sector', 'Industry Group', 'Industry Subgroup']\n",
    "    log_columns = ['Offer Price', 'Market Cap at Offer (M)']\n",
    "    exclude_columns = oe_columns + log_columns + ohe_columns\n",
    "    ss_columns = [col for col in X.select_dtypes(exclude=['object']).columns if col not in exclude_columns]\n",
    "\n",
    "    oe = OrdinalEncoder()\n",
    "    log = LogTransformer()\n",
    "    ohe = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "    ss = StandardScaler()\n",
    "\n",
    "    preprocess = ColumnTransformer(transformers=[\n",
    "        ('ohe', ohe, ohe_columns),\n",
    "        ('log', log, log_columns),\n",
    "        ('ss', ss, ss_columns),\n",
    "        ('oe', oe, oe_columns)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "    transformed_train = preprocess.fit_transform(X_train)\n",
    "    transformed_val = preprocess.transform(X_val)\n",
    "    transformed_test = preprocess.transform(X_test)\n",
    "\n",
    "    features = preprocess.get_feature_names_out()\n",
    "\n",
    "    df_train = pd.DataFrame(transformed_train, columns=features).reset_index(drop=True)\n",
    "    df_val = pd.DataFrame(transformed_val, columns=features).reset_index(drop=True)\n",
    "    df_test = pd.DataFrame(transformed_test, columns=features).reset_index(drop=True)\n",
    "\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    y_val = y_val.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    df_train = pd.concat([df_train, y_train], axis=1)\n",
    "    df_val = pd.concat([df_val, y_val], axis=1)\n",
    "    df_test = pd.concat([df_test, y_test], axis=1)\n",
    "\n",
    "    return df_train, df_val, df_test, preprocess\n",
    "\n",
    "\n",
    "df_train_encoded, df_val_encoded, df_test_encoded, preprocess = encoding(df_drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importances(df):\n",
    "    \"\"\"\n",
    "    Calculate feature importance using a simple model\n",
    "    \"\"\"\n",
    "    X_train = df.drop(columns=['Underpriced'])\n",
    "    y_train = df['Underpriced']\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    print(importances.sort_values(ascending=False).head(10))\n",
    "\n",
    "show_feature_importances(df_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation(df_train, df_val, df_test):\n",
    "    \"\"\"\n",
    "    Check correlation in the X_dev column and drop highly correlated features.\n",
    "    \"\"\"\n",
    "    X_train = df_train.drop(columns=['Underpriced'])\n",
    "    y_train = df_train['Underpriced']\n",
    "\n",
    "    X_val = df_val.drop(columns=['Underpriced'])\n",
    "    y_val = df_val['Underpriced']\n",
    "\n",
    "    X_test = df_test.drop(columns=['Underpriced'])\n",
    "    y_test = df_test['Underpriced']\n",
    "\n",
    "    corr_matrix = X_train.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] >= 0.9)]\n",
    "\n",
    "    X_reduced_train = X_train.drop(columns=to_drop)\n",
    "    X_reduced_val = X_val.drop(columns=to_drop)\n",
    "    X_reduced_test = X_test.drop(columns=to_drop)\n",
    "\n",
    "    df_train = pd.concat([X_reduced_train, y_train.reset_index(drop=True)], axis=1)\n",
    "    df_val = pd.concat([X_reduced_val, y_val.reset_index(drop=True)], axis=1)\n",
    "    df_test = pd.concat([X_reduced_test, y_test.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    print(f\"Removed {len(to_drop)} correlated features.\")\n",
    "\n",
    "    df_train.to_csv('./output_csv/Final_Output_Class_train.csv', index=False)\n",
    "    df_val.to_csv('./output_csv/Final_Output_Class_val.csv', index=False)\n",
    "    df_test.to_csv('./output_csv/Final_Output_Class_test.csv', index=False)\n",
    "\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "df_train_correlation, df_val_correlation, df_test_correlation = get_correlation(df_train_encoded, df_val_encoded, df_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_distribution(df_train_correlation):\n",
    "    \"\"\"\n",
    "    Displaying pie plot to show target data imbalance.\n",
    "    \"\"\"\n",
    "    df = df_train_correlation.copy()\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    underpriced_counts = df['Underpriced'].value_counts()\n",
    "    display(underpriced_counts)\n",
    "    labels = ['Underpriced', 'Not Underpriced']\n",
    "    colors = ['lightblue', '#212351']\n",
    "\n",
    "    _, _, autotexts = plt.pie(\n",
    "        underpriced_counts, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', textprops={'color': 'black'}\n",
    "    )\n",
    "\n",
    "    for i, autotext in enumerate(autotexts):\n",
    "        if colors[i] == '#212351':\n",
    "            autotext.set_color('white')\n",
    "\n",
    "    plt.title('Classification Task: Underpriced vs Not Underpriced (Before Applying SMOTE)')\n",
    "    plt.show()\n",
    "    \n",
    "display_distribution(df_train_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkimbalance(df, outfile):\n",
    "    \"\"\"\n",
    "    Checking imbalance in the target data. \n",
    "\n",
    "    If imbalance, resample using SMOTE.\n",
    "    \"\"\"\n",
    "    X_train = df.drop(columns=['Underpriced'])\n",
    "    y_train = df['Underpriced']\n",
    "\n",
    "    label_count_norm = df['Underpriced'].value_counts(normalize=True)\n",
    "    label_count = df['Underpriced'].value_counts()\n",
    "\n",
    "    print(f\"Class distribution (normalized):\\n{label_count_norm}\\n\")\n",
    "    print(f\"Class distribution:\\n{label_count}\\n\")\n",
    "\n",
    "    imbalance = abs(label_count_norm[0] - 0.5) > 0.1\n",
    "\n",
    "    if imbalance:\n",
    "        print('The data is imbalanced. Applying SMOTE...')\n",
    "        sampler = SMOTE(random_state=42)\n",
    "        X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "        df_final = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "        df_final.to_csv(outfile, index=False)\n",
    "        print(f'The initial dataset had {y_train.shape[0]} rows')\n",
    "        print(f'The resampled dataset has {y_resampled.shape[0]} rows')\n",
    "        print(f'Resampled feature matrix shape: {X_resampled.shape}')\n",
    "        return df_final\n",
    "    else:\n",
    "        print('The data is balanced. No resampling applied.')\n",
    "        return df\n",
    "    \n",
    "df_train_resampled = checkimbalance(df_train_correlation, './output_csv/Final_Output_Class_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkimbalance_undersampling(df, outfile):\n",
    "    \"\"\"\n",
    "    Checking imbalance in the target data. \n",
    "\n",
    "    If imbalance, resample using Undersamping.\n",
    "    \"\"\"\n",
    "    X_train = df.drop(columns=['Underpriced'])\n",
    "    y_train = df['Underpriced']\n",
    "\n",
    "    label_count_norm = df['Underpriced'].value_counts(normalize=True)\n",
    "    label_count = df['Underpriced'].value_counts()\n",
    "    print(f\"Class distribution (normalized):\\n{label_count_norm}\\n\")\n",
    "    print(f\"Class distribution:\\n{label_count}\\n\")\n",
    "\n",
    "\n",
    "    imbalance = abs(label_count_norm[0] - 0.5) > 0.1\n",
    "\n",
    "    if imbalance:\n",
    "        print('The data is imbalanced. Applying UnderSampling...')\n",
    "        sampler = RandomUnderSampler(sampling_strategy=0.8, random_state=42)\n",
    "        X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "        df_final = pd.concat([pd.DataFrame(X_resampled, columns=X_train.columns),\n",
    "                              pd.Series(y_resampled, name='Underpriced')], axis=1)\n",
    "        df_final.to_csv(outfile, index=False)\n",
    "        print(f'The initial dataset had {y_train.shape[0]} rows')\n",
    "        print(f'The resampled dataset has {y_resampled.shape[0]} rows')\n",
    "        print(f'Resampled feature matrix shape: {X_resampled.shape}')\n",
    "        return df_final\n",
    "    else:\n",
    "        print('The data is balanced. No resampling applied.')\n",
    "        return df\n",
    "\n",
    "df_train_resampled_under = checkimbalance_undersampling(df_train_correlation, './output_csv/Final_Output_Class_train_under.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_tomek(df, outfile):\n",
    "    \"\"\"\n",
    "    Checking imbalance in the target data. \n",
    "\n",
    "    If imbalance, resample using SMOTE.\n",
    "    \"\"\"\n",
    "    X_train = df.drop(columns=['Underpriced'])\n",
    "    y_train = df['Underpriced']\n",
    "\n",
    "    label_count_norm = df['Underpriced'].value_counts(normalize=True)\n",
    "    label_count = df['Underpriced'].value_counts()\n",
    "    print(f\"Class distribution (normalized):\\n{label_count_norm}\\n\")\n",
    "    print(f\"Class distribution:\\n{label_count}\\n\")\n",
    "\n",
    "\n",
    "    imbalance = abs(label_count_norm[0] - 0.5) > 0.1\n",
    "\n",
    "    if imbalance:\n",
    "        print('The data is imbalanced. Applying SMOTE...')\n",
    "        sampler = SMOTETomek(random_state=42)\n",
    "        X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "        df_final = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "        df_final.to_csv(outfile, index=False)\n",
    "        print(f'The initial dataset had {y_train.shape[0]} rows')\n",
    "        print(f'The resampled dataset has {y_resampled.shape[0]} rows')\n",
    "        print(f'Resampled feature matrix shape: {X_resampled.shape}')\n",
    "        return df_final\n",
    "    else:\n",
    "        print('The data is balanced. No resampling applied.')\n",
    "        return df\n",
    "    \n",
    "df_train_resampled_tomek = smote_tomek(df_train_correlation, './output_csv/Final_Output_Class_train_tomek.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enhanced_model_params():\n",
    "    \"\"\"\n",
    "    Return enhanced classification models with wider search space\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"Dummy Classifier\": {\n",
    "            \"model\": DummyClassifier(strategy='most_frequent'),\n",
    "            \"params\": {}\n",
    "        },\n",
    "        # \"Logistic Regression\": {\n",
    "        #     \"model\": LogisticRegression(solver='lbfgs', random_state=42, max_iter=10000, tol=1e-3),\n",
    "        #     \"params\": {\n",
    "        #         \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "        #         \"penalty\": ['l1', 'l2']\n",
    "        #     }\n",
    "        # },\n",
    "        \"Ridge Classifier\": {\n",
    "            \"model\": RidgeClassifier(max_iter=10000, tol=1e-3),\n",
    "            \"params\": {\n",
    "                \"alpha\": [0.1, 1.0, 10.0]\n",
    "            }\n",
    "        },\n",
    "        \"Random Forest Classifier\": {\n",
    "            \"model\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "            \"params\": {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [10, 15],\n",
    "                'min_samples_split': [5, 10],\n",
    "                'min_samples_leaf': [3, 5],\n",
    "                'max_features': ['sqrt'],\n",
    "                'bootstrap': [True],\n",
    "                'criterion': ['gini']\n",
    "            }\n",
    "        },\n",
    "        \"K-Nearest Neighbors\": {\n",
    "            \"model\": KNeighborsClassifier(),\n",
    "            \"params\": {\n",
    "                \"n_neighbors\": [3, 5, 7],\n",
    "                \"weights\": [\"uniform\", \"distance\"]\n",
    "            }\n",
    "        },\n",
    "        \"Gaussian Naive Bayes\": {\n",
    "            \"model\": GaussianNB(),\n",
    "            \"params\": {\n",
    "                \"var_smoothing\": [1e-9, 1e-8, 1e-7]\n",
    "            }\n",
    "        },\n",
    "        \"Decision Tree\": {\n",
    "            \"model\": DecisionTreeClassifier(random_state=42),\n",
    "            \"params\": {\n",
    "                \"max_depth\": [None, 5, 10, 15],\n",
    "                \"min_samples_split\": [2, 5, 10],\n",
    "                \"min_samples_leaf\": [1, 2, 4]\n",
    "            }\n",
    "        },\n",
    "        \"Shallow MLP\": {\n",
    "            \"model\": MLPClassifier(random_state=42, max_iter=1000, early_stopping=True),\n",
    "            \"params\": {\n",
    "                \"hidden_layer_sizes\": [(50,), (100,)],\n",
    "                \"alpha\": [0.0001, 0.001],\n",
    "                \"activation\": [\"relu\", \"tanh\"]\n",
    "            }\n",
    "        },\n",
    "        \"LightGBM\": {\n",
    "            \"model\": LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1),\n",
    "            \"params\": {\n",
    "                \"n_estimators\": [100, 200],\n",
    "                \"learning_rate\": [0.01, 0.1],\n",
    "                \"max_depth\": [3, 5, 7],\n",
    "                \"num_leaves\": [31, 63]\n",
    "            }\n",
    "        },\n",
    "        \"SGD Classifier\": {\n",
    "            \"model\": SGDClassifier(random_state=42, max_iter=1000, tol=1e-3),\n",
    "            \"params\": {\n",
    "                \"alpha\": [0.0001, 0.001, 0.01],\n",
    "                \"loss\": [\"hinge\", \"log_loss\"],\n",
    "                \"penalty\": [\"l2\", \"l1\", \"elasticnet\"]\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(model_params, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Evaluate classification models with multiple metrics\"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Initialize stratified k-fold\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    total_models = len(model_params)\n",
    "    print(f\"Evaluating {total_models} models...\\n\")\n",
    "\n",
    "    for i, (name, mp) in enumerate(model_params.items(), 1):\n",
    "        print(f\"[{i}/{total_models}] Training and evaluating: {name}...\", end=\" \")\n",
    "\n",
    "        try:\n",
    "            if mp[\"params\"]:\n",
    "                grid = GridSearchCV(\n",
    "                    mp[\"model\"],\n",
    "                    mp[\"params\"],\n",
    "                    cv=skf,\n",
    "                    scoring='f1',\n",
    "                    n_jobs=-1,\n",
    "                    verbose=0\n",
    "                )\n",
    "                grid.fit(X_train, y_train)\n",
    "                best_model = grid.best_estimator_\n",
    "                print(\"✓ (GridSearch complete)\")\n",
    "            else:\n",
    "                best_model = mp[\"model\"]\n",
    "                best_model.fit(X_train, y_train)\n",
    "                print(\"✓ (No tuning needed)\")\n",
    "\n",
    "            cv_scores = cross_val_score(best_model, X_train, y_train, cv=skf, scoring='f1')\n",
    "\n",
    "            y_pred = best_model.predict(X_val)\n",
    "\n",
    "            acc = accuracy_score(y_val, y_pred)\n",
    "            f1 = f1_score(y_val, y_pred, zero_division=0)\n",
    "            precision = precision_score(y_val, y_pred, zero_division=0)\n",
    "            recall = recall_score(y_val, y_pred, zero_division=0)\n",
    "\n",
    "            results.append({\n",
    "                \"Model\": name,\n",
    "                \"Accuracy\": acc,\n",
    "                \"F1 Score\": f1,\n",
    "                \"Precision\": precision,\n",
    "                \"Recall\": recall,\n",
    "                \"CV F1 Mean\": cv_scores.mean(),\n",
    "                \"CV F1 Std\": cv_scores.std()\n",
    "            })\n",
    "\n",
    "            train_sizes, train_scores, val_scores = learning_curve(\n",
    "                best_model, X_train, y_train, cv=skf, scoring='f1',\n",
    "                train_sizes=np.linspace(0.1, 1.0, 10)\n",
    "            )\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(train_sizes, train_scores.mean(axis=1), label='Training score')\n",
    "            plt.plot(train_sizes, val_scores.mean(axis=1), label='Cross-validation score')\n",
    "            plt.fill_between(train_sizes,\n",
    "                           train_scores.mean(axis=1) - train_scores.std(axis=1),\n",
    "                           train_scores.mean(axis=1) + train_scores.std(axis=1),\n",
    "                           alpha=0.1)\n",
    "            plt.fill_between(train_sizes,\n",
    "                           val_scores.mean(axis=1) - val_scores.std(axis=1),\n",
    "                           val_scores.mean(axis=1) + val_scores.std(axis=1),\n",
    "                           alpha=0.1)\n",
    "            plt.title(f'Learning Curves - {name}')\n",
    "            plt.xlabel('Training examples')\n",
    "            plt.ylabel('F1 Score')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error with {name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    top5_models_df = results_df.sort_values(by=\"F1 Score\", ascending=False).head(5).reset_index(drop=True)\n",
    "\n",
    "    return results_df, top5_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_names(df):\n",
    "    df.columns = df.columns.str.replace(r\"[^\\w\\d_]+\", \"_\", regex=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_best_model(model_params, X_dev, y_dev, X_test, y_test, top5_models_df):\n",
    "    \"\"\"\n",
    "    Evaluate the best model on the test set\n",
    "    \"\"\"\n",
    "    best_model_name = top5_models_df.iloc[0]['Model']\n",
    "    best_model = model_params[best_model_name]['model']\n",
    "    best_model.fit(X_dev, y_dev)\n",
    "\n",
    "    dummy_model = model_params['Dummy Classifier']['model']\n",
    "    dummy_model.fit(X_dev, y_dev)\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred_dummy = dummy_model.predict(X_test)\n",
    "\n",
    "\n",
    "    test_metrics = {\n",
    "        \"Model\": best_model_name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, zero_division=0),\n",
    "        \"Precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "        \"Dummy Accuracy\": accuracy_score(y_test, y_pred_dummy),\n",
    "        \"Dummy Precision\": precision_score(y_test, y_pred_dummy, zero_division=0),\n",
    "        \"Dummy Recall\": recall_score(y_test, y_pred_dummy, zero_division=0),\n",
    "        \"Dummy F1 Score\": f1_score(y_test, y_pred_dummy, zero_division=0)\n",
    "    }\n",
    "\n",
    "    metrics_df = pd.DataFrame([test_metrics])\n",
    "    metrics_df.to_csv('./output_csv/best_model_Class_test_results.csv', index=False)\n",
    "\n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        df_train = pd.read_csv('./output_csv/Final_Output_Class_train_tomek.csv')\n",
    "        df_val = pd.read_csv('./output_csv/Final_Output_Class_val.csv')\n",
    "        df_test = pd.read_csv('./output_csv/Final_Output_Class_test.csv')\n",
    "        \n",
    "        X_train = clean_column_names(df_train.drop(columns=['Underpriced']))\n",
    "        y_train = df_train['Underpriced']\n",
    "\n",
    "        X_val = clean_column_names(df_val.drop(columns=['Underpriced']))\n",
    "        y_val = df_val['Underpriced']\n",
    "\n",
    "        X_test = clean_column_names(df_test.drop(columns=['Underpriced']))\n",
    "        y_test = df_test['Underpriced']\n",
    "\n",
    "        model_params = get_enhanced_model_params()\n",
    "        results_df, top5_models_df = evaluate_models(model_params, X_train, y_train, X_val, y_val)\n",
    "\n",
    "        print(\"\\nTop 5 Models:\")\n",
    "        display(top5_models_df)\n",
    "\n",
    "        results_df.to_csv('./output_csv/classification_results.csv', index=False)\n",
    "        top5_models_df.to_csv('./output_csv/top5_classification_models.csv', index=False)\n",
    "\n",
    "        X_dev = pd.concat([X_train, X_val])\n",
    "        y_dev = pd.concat([y_train, y_val])\n",
    "\n",
    "        evaluate_best_model(model_params, X_dev, y_dev, X_test, y_test, top5_models_df)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
