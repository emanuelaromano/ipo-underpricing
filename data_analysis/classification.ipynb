{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../build_dataset/output_csv/bloomberg_data.csv\")\n",
    "df = df.dropna(subset=['Offer To 1st Close'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_features(df):\n",
    "    \"\"\"\n",
    "    Convert the 'Trade Date (US)' column to separate columns for\n",
    "    month, day, and year, and drop the original 'Trade Date (US)' column.\n",
    "\n",
    "    Also, convert Offer To 1st Close to a binary classification (Underpriced\n",
    "    column) and drop original column.\n",
    "    \"\"\"\n",
    "    df['Trade Date (US)'] = pd.to_datetime(df['Trade Date (US)'])\n",
    "    df['Trade Month'] = df['Trade Date (US)'].dt.month\n",
    "    df['Trade Day'] = df['Trade Date (US)'].dt.day\n",
    "    df['Trade Year'] = df['Trade Date (US)'].dt.year\n",
    "    df['Underpriced'] = df['Offer To 1st Close'].apply(lambda x: 1 if x < 0 else 0)  \n",
    "    df = df.sort_values('Trade Date (US)')\n",
    "    df['Prev_5_IPOs_Underpriced'] = df['Underpriced'].shift(1).rolling(window=5, min_periods=1).mean()\n",
    "    df['Prev_5_IPOs_Underpriced'] = df['Prev_5_IPOs_Underpriced'].apply(lambda x: 1 if x >= 0.6 else 0)\n",
    "    df.drop(columns=['Trade Date (US)'], inplace=True)\n",
    "    df.drop(columns=['Offer To 1st Close'], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_convert_features = convert_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(columns,df):\n",
    "    \"\"\"\n",
    "    Drop the specified columns from the DataFrame.\n",
    "    \"\"\"\n",
    "    df = df.drop(columns=columns)\n",
    "    return df\n",
    "\n",
    "df_drop_columns = drop_columns(['Issuer Ticker',\n",
    "                                'Issuer Name',\n",
    "                                'Filing Term Price Range',\n",
    "                                'cusip',\n",
    "                                'Priced Range'],\n",
    "                                df_convert_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(df):\n",
    "    \"\"\"\n",
    "    Split the DataFrame into development and testing sets, using stratified sampling. \n",
    "    \n",
    "    Fill missing values with the mode for categorical \n",
    "    columns and the mean for numerical columns.\n",
    "\n",
    "    Encode columns in the DataFrame: \n",
    "\n",
    "      - Categorical columns are encoded using OneHotEncoder.\n",
    "      - Numerical columns are scaled using StandardScaler.\n",
    "      - Ordinal columns are encoded using OrdinalEncoder.\n",
    "\n",
    "    Create df_dev and df_test using the transformed features.\n",
    "    \"\"\"\n",
    "\n",
    "    X = df.drop(columns=['Underpriced'])\n",
    "    y = df['Underpriced']\n",
    "\n",
    "    X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    for col in X_dev.columns:\n",
    "        if X_dev[col].dtype == 'object':\n",
    "            mode = X_dev[col].mode()[0]\n",
    "            X_dev[col] = X_dev[col].fillna(mode)\n",
    "            X_test[col] = X_test[col].fillna(mode)\n",
    "        else:\n",
    "            mean = X_dev[col].mean()\n",
    "            X_dev[col] = X_dev[col].fillna(mean)\n",
    "            X_test[col] = X_test[col].fillna(mean)\n",
    "\n",
    "\n",
    "    oe_columns = ['Trade Month', 'Trade Day', 'Trade Year'] \n",
    "    ohe_columns = ['Industry Sector', 'Industry Group', 'Industry Subgroup']\n",
    "    ss_columns = [col for col in X.select_dtypes(exclude=['object']).columns if col not in oe_columns]\n",
    "\n",
    "    oe = OrdinalEncoder()\n",
    "    ohe = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "    ss = StandardScaler()\n",
    "\n",
    "    preprocess = ColumnTransformer(transformers=[\n",
    "        ('ohe', ohe, ohe_columns),\n",
    "        ('ss', ss, ss_columns),\n",
    "        ('oe', oe, oe_columns)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "    transformed_dev = preprocess.fit_transform(X_dev)\n",
    "    transformed_test = preprocess.transform(X_test)\n",
    "\n",
    "    features = preprocess.get_feature_names_out()\n",
    "\n",
    "    df_dev = pd.DataFrame(transformed_dev, columns=features)\n",
    "    df_test = pd.DataFrame(transformed_test, columns=features)\n",
    "\n",
    "    df_dev['Underpriced'] = y_dev.reset_index(drop=True)\n",
    "    df_test['Underpriced'] = y_test.reset_index(drop=True)\n",
    "\n",
    "    assert not df_dev.isnull().any().any(), \"Missing values found in development set\"\n",
    "    assert not df_test.isnull().any().any(), \"Missing values found in test set\"\n",
    "    assert len(df_dev.columns) == len(df_test.columns), \"Mismatch in number of features\"\n",
    "    assert 'Underpriced' in df_dev.columns and 'Underpriced' in df_test.columns, \"Target column missing\"\n",
    "                \n",
    "    return df_dev, df_test\n",
    "\n",
    "df_dev_encoding, df_test_encoding = encoding(df_drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importances(df_dev):\n",
    "    \"\"\"\n",
    "    Calculate feature importance using a simple model\n",
    "    \"\"\"\n",
    "    X_dev = df_dev.drop(columns=['Underpriced'])\n",
    "    y_dev = df_dev['Underpriced']\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_dev, y_dev)\n",
    "    importances = pd.Series(rf.feature_importances_, index=X_dev.columns)\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    print(importances.sort_values(ascending=False).head(10))\n",
    "\n",
    "show_feature_importances(df_dev_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation(df_dev, df_test, outfile):\n",
    "    \"\"\"\n",
    "    Check correlation in the X_dev column and drop highly correlated features.\n",
    "    \"\"\"\n",
    "\n",
    "    X_dev = df_dev.drop(columns=['Underpriced'])\n",
    "    corr_matrix = X_dev.corr().abs()\n",
    "    \n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] >= 0.9)]\n",
    "    \n",
    "    X_dev_reduced = X_dev.drop(columns=to_drop)\n",
    "    X_test_reduced = df_test.drop(columns=['Underpriced']).drop(columns=to_drop)\n",
    "\n",
    "    df_dev = pd.concat([X_dev_reduced, df_dev['Underpriced'].reset_index(drop=True)], axis=1)\n",
    "    df_test = pd.concat([X_test_reduced, df_test['Underpriced'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "    print(f\"Removed {len(to_drop)} correlated features.\")\n",
    "    df_test.to_csv(outfile, index=False)\n",
    "\n",
    "    return df_dev, df_test\n",
    "\n",
    "df_dev_correlation, df_test_correlation = get_correlation(df_dev_encoding, df_test_encoding, './output_csv/Final_Output_Class_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_distribution(df_dev_correlation):\n",
    "    \"\"\"\n",
    "    Displaying pie plot to show target data imbalance.\n",
    "    \"\"\"\n",
    "    df = df_dev_correlation.copy()\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    underpriced_counts = df['Underpriced'].value_counts()\n",
    "    display(underpriced_counts)\n",
    "    labels = ['Underpriced', 'Not Underpriced']\n",
    "    colors = ['lightblue', '#212351']\n",
    "\n",
    "    wedges, texts, autotexts = plt.pie(\n",
    "        underpriced_counts, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', textprops={'color': 'black'}\n",
    "    )\n",
    "\n",
    "    for i, autotext in enumerate(autotexts):\n",
    "        if colors[i] == '#212351':\n",
    "            autotext.set_color('white')\n",
    "\n",
    "    plt.title('Classification Task: Underpriced vs Not Underpriced (Before Applying SMOTE)')\n",
    "    plt.show()\n",
    "    \n",
    "display_distribution(df_dev_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkimbalance(df, outfile):\n",
    "    \"\"\"\n",
    "    Checking imbalance in the target data. \n",
    "\n",
    "    If imbalance, resample using SMOTE.\n",
    "    \"\"\"\n",
    "    X_dev = df.drop(columns=['Underpriced'])\n",
    "    y_dev = df['Underpriced']\n",
    "\n",
    "    label_count_norm = df['Underpriced'].value_counts(normalize=True)\n",
    "    label_count = df['Underpriced'].value_counts()\n",
    "    print(f\"Class distribution (normalized):\\n{label_count_norm}\\n\")\n",
    "    print(f\"Class distribution:\\n{label_count}\\n\")\n",
    "\n",
    "\n",
    "    imbalance = abs(label_count_norm[0] - 0.5) > 0.1\n",
    "\n",
    "    if imbalance:\n",
    "        print('The data is imbalanced. Applying SMOTE...')\n",
    "        sampler = SMOTE(random_state=42)\n",
    "        X_resampled, y_resampled = sampler.fit_resample(X_dev, y_dev)\n",
    "        df_final = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "        df_final.to_csv(outfile, index=False)\n",
    "        print(f'The initial dataset had {y_dev.shape[0]} rows')\n",
    "        print(f'The resampled dataset has {y_resampled.shape[0]} rows')\n",
    "        print(f'Resampled feature matrix shape: {X_resampled.shape}')\n",
    "        return df_final\n",
    "    else:\n",
    "        print('The data is balanced. No resampling applied.')\n",
    "        return df\n",
    "    \n",
    "df_dev_resampled = checkimbalance(df_dev_correlation, './output_csv/Final_Output_Class_dev.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, target_col='Underpriced'):\n",
    "    \"\"\"\n",
    "    Preprocess the data with feature engineering and scaling\n",
    "    \"\"\"\n",
    "    X = df.drop(columns=target_col)\n",
    "    y = df[target_col]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enhanced_model_params():\n",
    "    \"\"\"\n",
    "    Return enhanced classification models with wider search space\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"Logistic Regression\": {\n",
    "            \"model\": LogisticRegression(solver='liblinear', random_state=42, max_iter=10000, tol=1e-3),\n",
    "            \"params\": {\n",
    "                \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "                \"penalty\": ['l1', 'l2']\n",
    "            }\n",
    "        },\n",
    "        \"Ridge Classifier\": {\n",
    "            \"model\": RidgeClassifier(max_iter=10000, tol=1e-3),\n",
    "            \"params\": {\n",
    "                \"alpha\": [0.1, 1.0, 10.0]\n",
    "            }\n",
    "        },\n",
    "        \"Random Forest Classifier\": {\n",
    "            \"model\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "            \"params\": {\n",
    "                \"n_estimators\": [100, 200],\n",
    "                \"max_depth\": [None, 10, 20],\n",
    "                \"max_features\": [\"sqrt\", \"log2\"]\n",
    "            }\n",
    "        },\n",
    "        \"K-Nearest Neighbors\": {\n",
    "            \"model\": KNeighborsClassifier(),\n",
    "            \"params\": {\n",
    "                \"n_neighbors\": [3, 5, 7],\n",
    "                \"weights\": [\"uniform\", \"distance\"]\n",
    "            }\n",
    "        },\n",
    "        \"Gaussian Naive Bayes\": {\n",
    "            \"model\": GaussianNB(),\n",
    "            \"params\": {\n",
    "                \"var_smoothing\": [1e-9, 1e-8, 1e-7]\n",
    "            }\n",
    "        },\n",
    "        \"Decision Tree\": {\n",
    "            \"model\": DecisionTreeClassifier(random_state=42),\n",
    "            \"params\": {\n",
    "                \"max_depth\": [None, 5, 10, 15],\n",
    "                \"min_samples_split\": [2, 5, 10],\n",
    "                \"min_samples_leaf\": [1, 2, 4]\n",
    "            }\n",
    "        },\n",
    "        \"Shallow MLP\": {\n",
    "            \"model\": MLPClassifier(random_state=42, max_iter=1000, early_stopping=True),\n",
    "            \"params\": {\n",
    "                \"hidden_layer_sizes\": [(50,), (100,)],\n",
    "                \"alpha\": [0.0001, 0.001],\n",
    "                \"activation\": [\"relu\", \"tanh\"]\n",
    "            }\n",
    "        },\n",
    "        \"LightGBM\": {\n",
    "            \"model\": LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1),\n",
    "            \"params\": {\n",
    "                \"n_estimators\": [100, 200],\n",
    "                \"learning_rate\": [0.01, 0.1],\n",
    "                \"max_depth\": [3, 5, 7],\n",
    "                \"num_leaves\": [31, 63]\n",
    "            }\n",
    "        },\n",
    "        \"SGD Classifier\": {\n",
    "            \"model\": SGDClassifier(random_state=42, max_iter=1000, tol=1e-3),\n",
    "            \"params\": {\n",
    "                \"alpha\": [0.0001, 0.001, 0.01],\n",
    "                \"loss\": [\"hinge\", \"log_loss\"],\n",
    "                \"penalty\": [\"l2\", \"l1\", \"elasticnet\"]\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(model_params, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Evaluate classification models with multiple metrics\"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Initialize stratified k-fold\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    total_models = len(model_params)\n",
    "    print(f\"Evaluating {total_models} models...\\n\")\n",
    "\n",
    "    for i, (name, mp) in enumerate(model_params.items(), 1):\n",
    "        print(f\"[{i}/{total_models}] Training and evaluating: {name}...\", end=\" \")\n",
    "\n",
    "        try:\n",
    "            if mp[\"params\"]:\n",
    "                grid = GridSearchCV(\n",
    "                    mp[\"model\"],\n",
    "                    mp[\"params\"],\n",
    "                    cv=skf,\n",
    "                    scoring='f1',\n",
    "                    n_jobs=-1,\n",
    "                    verbose=0\n",
    "                )\n",
    "                grid.fit(X_train, y_train)\n",
    "                best_model = grid.best_estimator_\n",
    "                print(\"✓ (GridSearch complete)\")\n",
    "            else:\n",
    "                best_model = mp[\"model\"]\n",
    "                best_model.fit(X_train, y_train)\n",
    "                print(\"✓ (No tuning needed)\")\n",
    "\n",
    "            cv_scores = cross_val_score(best_model, X_train, y_train, cv=skf, scoring='f1')\n",
    "\n",
    "            y_pred = best_model.predict(X_val)\n",
    "\n",
    "            acc = accuracy_score(y_val, y_pred)\n",
    "            f1 = f1_score(y_val, y_pred, zero_division=0)\n",
    "            precision = precision_score(y_val, y_pred, zero_division=0)\n",
    "            recall = recall_score(y_val, y_pred, zero_division=0)\n",
    "\n",
    "            results.append({\n",
    "                \"Model\": name,\n",
    "                \"Accuracy\": acc,\n",
    "                \"F1 Score\": f1,\n",
    "                \"Precision\": precision,\n",
    "                \"Recall\": recall,\n",
    "                \"CV F1 Mean\": cv_scores.mean(),\n",
    "                \"CV F1 Std\": cv_scores.std()\n",
    "            })\n",
    "\n",
    "            train_sizes, train_scores, val_scores = learning_curve(\n",
    "                best_model, X_train, y_train, cv=skf, scoring='f1',\n",
    "                train_sizes=np.linspace(0.1, 1.0, 10)\n",
    "            )\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(train_sizes, train_scores.mean(axis=1), label='Training score')\n",
    "            plt.plot(train_sizes, val_scores.mean(axis=1), label='Cross-validation score')\n",
    "            plt.fill_between(train_sizes,\n",
    "                           train_scores.mean(axis=1) - train_scores.std(axis=1),\n",
    "                           train_scores.mean(axis=1) + train_scores.std(axis=1),\n",
    "                           alpha=0.1)\n",
    "            plt.fill_between(train_sizes,\n",
    "                           val_scores.mean(axis=1) - val_scores.std(axis=1),\n",
    "                           val_scores.mean(axis=1) + val_scores.std(axis=1),\n",
    "                           alpha=0.1)\n",
    "            plt.title(f'Learning Curves - {name}')\n",
    "            plt.xlabel('Training examples')\n",
    "            plt.ylabel('F1 Score')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error with {name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    top5_models_df = results_df.sort_values(by=\"F1 Score\", ascending=False).head(5).reset_index(drop=True)\n",
    "\n",
    "    return results_df, top5_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_names(df):\n",
    "    df.columns = df.columns.str.replace(r\"[^\\w\\d_]+\", \"_\", regex=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        df_dev = pd.read_csv('./output_csv/Final_Output_Class_dev.csv')\n",
    "        X, y = split_data(df_dev)\n",
    "        X = clean_column_names(X)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        model_params = get_enhanced_model_params()\n",
    "        results_df, top5_models_df = evaluate_models(model_params, X_train, y_train, X_val, y_val)\n",
    "\n",
    "\n",
    "        print(\"\\nTop 5 Models:\")\n",
    "        display(top5_models_df)\n",
    "        \n",
    "        results_df.to_csv('./output_csv/classification_results.csv', index=False)\n",
    "        top5_models_df.to_csv('./output_csv/top5_classification_models.csv', index=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
