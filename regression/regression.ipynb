{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data loading & Train/Validation split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./Final_Output_Reg_dev.csv')\n",
    "\n",
    "X_train = train_data.drop(columns=['Offer To 1st Close'])\n",
    "y_train = train_data['Offer To 1st Close']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"ElasticNet Regression\": ElasticNet(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"SVM\": SVR(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    \"Ridge Regression\": {'alpha': [0.01, 0.1, 1, 10], 'max_iter': [1000, 2000, 5000]},\n",
    "    \"Lasso Regression\": {'alpha': [0.01, 0.1, 1, 10], 'max_iter': [1000, 2000, 5000]},\n",
    "    \"ElasticNet Regression\": {'alpha': [0.01, 0.1, 1, 10], 'l1_ratio': [0.1, 0.5, 0.9], 'max_iter': [1000, 2000, 5000]},\n",
    "    \n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [50, 100, 200, 500, 1000],\n",
    "        'max_depth': [None, 10, 20, 30],  \n",
    "        'min_samples_split': [2, 5, 10],  \n",
    "        'min_samples_leaf': [1, 2, 4]  \n",
    "    },\n",
    "    \n",
    "    \"Decision Tree\": {\n",
    "        'max_depth': [None, 10, 20, 30],  \n",
    "        'min_samples_split': [2, 5, 10],  \n",
    "        'min_samples_leaf': [1, 2, 4]  \n",
    "    },\n",
    "    \n",
    "    \"SVM\": {\n",
    "        'C': [0.1, 1, 10, 100],  \n",
    "        'gamma': ['scale', 'auto', 0.01, 0.1],  \n",
    "        'kernel': ['linear', 'rbf']  \n",
    "    },\n",
    "    \n",
    "    \"Gradient Boosting\": {\n",
    "        'n_estimators': [50, 100, 200, 500], \n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],  \n",
    "        'max_depth': [3, 5, 10, 20] \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression...\n",
      "Using default Linear Regression with no parameter tuning.\n",
      "Training Ridge Regression...\n",
      "Best parameters for Ridge Regression: {'alpha': 10, 'max_iter': 1000}\n",
      "Best score for Ridge Regression: -142.8974383680772\n",
      "Training Lasso Regression...\n",
      "Best parameters for Lasso Regression: {'alpha': 0.1, 'max_iter': 1000}\n",
      "Best score for Lasso Regression: -130.26267660799377\n",
      "Training ElasticNet Regression...\n",
      "Best parameters for ElasticNet Regression: {'alpha': 0.1, 'l1_ratio': 0.9, 'max_iter': 1000}\n",
      "Best score for ElasticNet Regression: -130.35570127767406\n",
      "Training Random Forest...\n",
      "Best parameters for Random Forest: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best score for Random Forest: -118.48466592150291\n",
      "Training Decision Tree...\n",
      "Best parameters for Decision Tree: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "Best score for Decision Tree: -161.3756324227868\n",
      "Training SVM...\n",
      "Best parameters for SVM: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best score for SVM: -135.9729690307084\n",
      "Training Gradient Boosting...\n",
      "Best parameters for Gradient Boosting: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500}\n",
      "Best score for Gradient Boosting: -120.6736552215688\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    if model_name == \"Linear Regression\":\n",
    "        model.fit(X_train, y_train)\n",
    "        best_models[model_name] = model\n",
    "        print(f\"Using default Linear Regression with no parameter tuning.\")\n",
    "    elif model_name in param_grid:\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid[model_name], cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_models[model_name] = grid_search.best_estimator_\n",
    "        print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "        print(f\"Best score for {model_name}: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Linear Regression on validation set:\n",
      "Mean Squared Error: 142.07265083106634\n",
      "R2 Score: -0.10471379419688653\n",
      "\n",
      "Evaluating Ridge Regression on validation set:\n",
      "Mean Squared Error: 118.66406369536806\n",
      "R2 Score: 0.0773042716320862\n",
      "\n",
      "Evaluating Lasso Regression on validation set:\n",
      "Mean Squared Error: 113.60598722031932\n",
      "R2 Score: 0.11663433847748672\n",
      "\n",
      "Evaluating ElasticNet Regression on validation set:\n",
      "Mean Squared Error: 114.21246858510655\n",
      "R2 Score: 0.11191852353573228\n",
      "\n",
      "Evaluating Random Forest on validation set:\n",
      "Mean Squared Error: 103.07808178426497\n",
      "R2 Score: 0.19849613447535852\n",
      "\n",
      "Evaluating Decision Tree on validation set:\n",
      "Mean Squared Error: 162.23086653859195\n",
      "R2 Score: -0.2614579587368955\n",
      "\n",
      "Evaluating SVM on validation set:\n",
      "Mean Squared Error: 114.7227067633869\n",
      "R2 Score: 0.10795106638915997\n",
      "\n",
      "Evaluating Gradient Boosting on validation set:\n",
      "Mean Squared Error: 105.298708195533\n",
      "R2 Score: 0.1812292177680559\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in best_models.items():\n",
    "    print(f\"\\nEvaluating {model_name} on validation set:\")\n",
    "    y_pred = model.predict(X_val)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Set Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./Final_Output_Reg_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop(columns=['Offer To 1st Close'])\n",
    "y_test = test_data['Offer To 1st Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Linear Regression on test set:\n",
      "Mean Squared Error: 1230.1863513040537\n",
      "R2 Score: -0.06813817487034113\n",
      "\n",
      "Evaluating Ridge Regression on test set:\n",
      "Mean Squared Error: 1169.1898778125824\n",
      "R2 Score: -0.01517655503149129\n",
      "\n",
      "Evaluating Lasso Regression on test set:\n",
      "Mean Squared Error: 1133.521937970702\n",
      "R2 Score: 0.015792970946183038\n",
      "\n",
      "Evaluating ElasticNet Regression on test set:\n",
      "Mean Squared Error: 1135.0427730422534\n",
      "R2 Score: 0.014472470197752774\n",
      "\n",
      "Evaluating Random Forest on test set:\n",
      "Mean Squared Error: 1085.6001872362467\n",
      "R2 Score: 0.0574021558569342\n",
      "\n",
      "Evaluating Decision Tree on test set:\n",
      "Mean Squared Error: 1100.5133264715942\n",
      "R2 Score: 0.04445347266958988\n",
      "\n",
      "Evaluating SVM on test set:\n",
      "Mean Squared Error: 1178.9751507737785\n",
      "R2 Score: -0.023672847963290167\n",
      "\n",
      "Evaluating Gradient Boosting on test set:\n",
      "Mean Squared Error: 1088.9496239179634\n",
      "R2 Score: 0.05449392883892168\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in best_models.items():\n",
    "    print(f\"\\nEvaluating {model_name} on test set:\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PCA Version*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./Final_Output_Reg_dev.csv')\n",
    "\n",
    "X_train = train_data.drop(columns=['Offer To 1st Close'])\n",
    "y_train = train_data['Offer To 1st Close']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "pca = PCA(n_components=0.95)  \n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"ElasticNet Regression\": ElasticNet(),\n",
    "    #\"Random Forest\": RandomForestRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    \"Ridge Regression\": {'alpha': [0.01, 0.1, 1, 10], 'max_iter': [1000, 2000, 5000]},\n",
    "    \"Lasso Regression\": {'alpha': [0.01, 0.1, 1, 10], 'max_iter': [1000, 2000, 5000]},\n",
    "    \"ElasticNet Regression\": {'alpha': [0.01, 0.1, 1, 10], 'l1_ratio': [0.1, 0.5, 0.9], 'max_iter': [1000, 2000, 5000]},\n",
    "    \n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [50, 100, 200, 500, 1000],\n",
    "        'max_depth': [None, 10, 20, 30],  \n",
    "        'min_samples_split': [2, 5, 10],  \n",
    "        'min_samples_leaf': [1, 2, 4]  \n",
    "    },\n",
    "    \n",
    "    \"Decision Tree\": {\n",
    "        'max_depth': [None, 10, 20, 30],  \n",
    "        'min_samples_split': [2, 5, 10],  \n",
    "        'min_samples_leaf': [1, 2, 4]  \n",
    "    },\n",
    "    \n",
    "    \"Gradient Boosting\": {\n",
    "        'n_estimators': [50, 100, 200, 500], \n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],  \n",
    "        'max_depth': [3, 5, 10, 20] \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression...\n",
      "Using default Linear Regression with no parameter tuning.\n",
      "Training Ridge Regression...\n",
      "Best parameters for Ridge Regression: {'alpha': 10, 'max_iter': 1000}\n",
      "Best score for Ridge Regression: -531.5157175381744\n",
      "Training Lasso Regression...\n",
      "Best parameters for Lasso Regression: {'alpha': 1, 'max_iter': 1000}\n",
      "Best score for Lasso Regression: -135.97083199947127\n",
      "Training ElasticNet Regression...\n",
      "Best parameters for ElasticNet Regression: {'alpha': 1, 'l1_ratio': 0.1, 'max_iter': 1000}\n",
      "Best score for ElasticNet Regression: -130.19091754411363\n",
      "Training Decision Tree...\n",
      "Best parameters for Decision Tree: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Best score for Decision Tree: -201.83311879424298\n",
      "Training Gradient Boosting...\n",
      "Best parameters for Gradient Boosting: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200}\n",
      "Best score for Gradient Boosting: -127.67293431747498\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    if model_name == \"Linear Regression\":\n",
    "        model.fit(X_train_pca, y_train)\n",
    "        best_models[model_name] = model\n",
    "        print(f\"Using default Linear Regression with no parameter tuning.\")\n",
    "    elif model_name in param_grid:\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid[model_name], cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train_pca, y_train)\n",
    "        best_models[model_name] = grid_search.best_estimator_\n",
    "        print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "        print(f\"Best score for {model_name}: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Linear Regression on validation set:\n",
      "Mean Squared Error: 124.26166612978415\n",
      "R2 Score: 0.03377901474726597\n",
      "\n",
      "Evaluating Ridge Regression on validation set:\n",
      "Mean Squared Error: 124.10772144786795\n",
      "R2 Score: 0.03497604185038017\n",
      "\n",
      "Evaluating Lasso Regression on validation set:\n",
      "Mean Squared Error: 121.96365583691923\n",
      "R2 Score: 0.05164764502117347\n",
      "\n",
      "Evaluating ElasticNet Regression on validation set:\n",
      "Mean Squared Error: 113.42141728626969\n",
      "R2 Score: 0.11806949824219826\n",
      "\n",
      "Evaluating Decision Tree on validation set:\n",
      "Mean Squared Error: 145.36039258094132\n",
      "R2 Score: -0.1302782757603549\n",
      "\n",
      "Evaluating Gradient Boosting on validation set:\n",
      "Mean Squared Error: 111.4449908212601\n",
      "R2 Score: 0.1334375903157955\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in best_models.items():\n",
    "    print(f\"\\nEvaluating {model_name} on validation set:\")\n",
    "    y_pred = model.predict(X_val_pca)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./Final_Output_Reg_test.csv')\n",
    "\n",
    "X_test = test_data.drop(columns=['Offer To 1st Close'])\n",
    "y_test = test_data['Offer To 1st Close']\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Linear Regression on test set:\n",
      "Mean Squared Error: 1164.6720993192396\n",
      "R2 Score: -0.011253887811819796\n",
      "\n",
      "Evaluating Ridge Regression on test set:\n",
      "Mean Squared Error: 1164.598059681806\n",
      "R2 Score: -0.011189601158734686\n",
      "\n",
      "Evaluating Lasso Regression on test set:\n",
      "Mean Squared Error: 1194.2435438236519\n",
      "R2 Score: -0.03692998861373442\n",
      "\n",
      "Evaluating ElasticNet Regression on test set:\n",
      "Mean Squared Error: 1173.9165082868567\n",
      "R2 Score: -0.019280562885850783\n",
      "\n",
      "Evaluating Decision Tree on test set:\n",
      "Mean Squared Error: 1156.0839328042357\n",
      "R2 Score: -0.003797010650815169\n",
      "\n",
      "Evaluating Gradient Boosting on test set:\n",
      "Mean Squared Error: 1145.240573888928\n",
      "R2 Score: 0.005617990246392979\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in best_models.items():\n",
    "    print(f\"\\nEvaluating {model_name} on test set:\")\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2025_spring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
